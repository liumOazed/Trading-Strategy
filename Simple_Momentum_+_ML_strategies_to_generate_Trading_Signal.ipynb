{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+Kf7pDvRgY8I4pR6uIbUZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liumOazed/Trading-Strategy/blob/main/Simple_Momentum_%2B_ML_strategies_to_generate_Trading_Signal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drives\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilvbne4bjgrK",
        "outputId": "8f253d74-af94-4980-abed-9fe6b9a656a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Set your working directory to the notebook's folder\n",
        "os.chdir(\"/content/drive/MyDrive/_Learning/Finance/Trading/Machine Learning for Trading - Specialization/2. Using ML in Trading & Finance/Module 4: Build a Momentum-based Trading System/\")"
      ],
      "metadata": {
        "id": "-45KRa-cjncK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Traditional Momentum Strategy"
      ],
      "metadata": {
        "id": "gIJHBmh6FrXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "MOMENTUM TRADING BACKTESTER\n",
        "A clean, library-independent backtesting system for momentum-based strategies\n",
        "================================================================================\n",
        "\"\"\"\n",
        "\n",
        "# ================================================================================\n",
        "# SECTION 1: LIBRARY IMPORTS\n",
        "# ================================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "WbaVz0AzDmUG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# SECTION 2: DATA ACQUISITION\n",
        "# ================================================================================\n",
        "\n",
        "def download_stock_data(symbol='AAPL', start_date='2014-06-01', end_date='2017-09-01'):\n",
        "    \"\"\"\n",
        "    Download historical stock data from Yahoo Finance\n",
        "\n",
        "    Args:\n",
        "        symbol: Stock ticker symbol\n",
        "        start_date: Start date in YYYY-MM-DD format\n",
        "        end_date: End date in YYYY-MM-DD format\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with OHLCV data\n",
        "    \"\"\"\n",
        "    print(f\"ðŸ“¥ Downloading {symbol} data from {start_date} to {end_date}...\")\n",
        "\n",
        "    # Download data\n",
        "    df = yf.download(symbol, start=start_date, end=end_date, progress=False, auto_adjust=False)\n",
        "\n",
        "    # Clean multi-level columns if present\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.droplevel(1)\n",
        "\n",
        "    # Remove timezone info if present\n",
        "    if df.index.tz is not None:\n",
        "        df.index = df.index.tz_localize(None)\n",
        "\n",
        "    # Standardize column names (lowercase, underscore-separated)\n",
        "    df.columns = [c.replace(' ', '_').lower() for c in df.columns]\n",
        "\n",
        "    # Create adjclose if it doesn't exist\n",
        "    if 'adj_close' in df.columns:\n",
        "        df['adjclose'] = df['adj_close']\n",
        "    elif 'adjclose' not in df.columns and 'close' in df.columns:\n",
        "        df['adjclose'] = df['close']\n",
        "\n",
        "    print(f\"âœ“ Downloaded {len(df)} trading days\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "plvVwNQ8D1tc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# SECTION 3: FEATURE ENGINEERING\n",
        "# ================================================================================\n",
        "\n",
        "def calculate_momentum_indicator(prices, period):\n",
        "    \"\"\"\n",
        "    Calculate momentum: difference between current price and price N periods ago\n",
        "\n",
        "    Args:\n",
        "        prices: Series of prices\n",
        "        period: Lookback period in days\n",
        "\n",
        "    Returns:\n",
        "        Series of momentum values\n",
        "    \"\"\"\n",
        "    return prices - prices.shift(period)\n",
        "\n",
        "\n",
        "def calculate_exponential_moving_average(prices, period):\n",
        "    \"\"\"\n",
        "    Calculate Exponential Moving Average (EMA)\n",
        "\n",
        "    Args:\n",
        "        prices: Series of prices\n",
        "        period: EMA period\n",
        "\n",
        "    Returns:\n",
        "        Series of EMA values\n",
        "    \"\"\"\n",
        "    return prices.ewm(span=period, adjust=False).mean()\n",
        "\n",
        "\n",
        "def engineer_features(df):\n",
        "    \"\"\"\n",
        "    Calculate all technical indicators and features\n",
        "\n",
        "    Features created:\n",
        "        - mom_10: 10-day momentum\n",
        "        - mom_30: 30-day momentum\n",
        "        - ma_90: 90-day exponential moving average\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with price data\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with added feature columns\n",
        "    \"\"\"\n",
        "    print(\"\\nðŸ”§ Engineering technical features...\")\n",
        "\n",
        "    # Use adjusted close price for all calculations\n",
        "    price = df['adjclose']\n",
        "\n",
        "    # Momentum indicators (short and medium term)\n",
        "    df['mom_10'] = calculate_momentum_indicator(price, period=10)\n",
        "    df['mom_30'] = calculate_momentum_indicator(price, period=30)\n",
        "\n",
        "    # Moving average (long term trend)\n",
        "    df['ma_90'] = calculate_exponential_moving_average(price, period=90)\n",
        "\n",
        "    # Remove rows with NaN values (warmup period for indicators)\n",
        "    initial_rows = len(df)\n",
        "    df = df.dropna()\n",
        "    removed_rows = initial_rows - len(df)\n",
        "\n",
        "    print(f\"âœ“ Features calculated\")\n",
        "    print(f\"  - Removed {removed_rows} warmup rows (indicator initialization)\")\n",
        "    print(f\"  - {len(df)} valid rows remaining\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "skllFlerEAvG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# SECTION 4: TRADING STRATEGY\n",
        "# ================================================================================\n",
        "\n",
        "def generate_trading_signals(df):\n",
        "    \"\"\"\n",
        "    Generate buy/sell signals based on momentum strategy\n",
        "\n",
        "    Strategy Logic:\n",
        "        - BUY (signal=1): When 30-day momentum is positive\n",
        "        - SELL (signal=0): When 30-day momentum is negative or zero\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with feature columns\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with signal and position columns\n",
        "    \"\"\"\n",
        "    print(\"\\nðŸ“Š Generating trading signals...\")\n",
        "\n",
        "    # Initialize signal column\n",
        "    df['signal'] = 0\n",
        "\n",
        "    # Buy signal: positive 30-day momentum\n",
        "    df.loc[df['mom_30'] > 0, 'signal'] = 1\n",
        "\n",
        "    # Sell signal: non-positive 30-day momentum\n",
        "    df.loc[df['mom_30'] <= 0, 'signal'] = 0\n",
        "\n",
        "    # Calculate position changes (for detecting entry/exit points)\n",
        "    df['position'] = df['signal'].diff()\n",
        "\n",
        "    # Count signals\n",
        "    buy_signals = (df['signal'] == 1).sum()\n",
        "    sell_signals = (df['signal'] == 0).sum()\n",
        "\n",
        "    print(f\"âœ“ Signals generated:\")\n",
        "    print(f\"  - {buy_signals} buy periods\")\n",
        "    print(f\"  - {sell_signals} sell/hold periods\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "4pStJv2JEE_W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# SECTION 4: TRADING STRATEGY\n",
        "# ================================================================================\n",
        "\n",
        "def generate_trading_signals(df):\n",
        "    \"\"\"\n",
        "    Generate buy/sell signals based on momentum strategy\n",
        "\n",
        "    Strategy Logic:\n",
        "        - BUY (signal=1): When 30-day momentum is positive\n",
        "        - SELL (signal=0): When 30-day momentum is negative or zero\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with feature columns\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with signal and position columns\n",
        "    \"\"\"\n",
        "    print(\"\\nðŸ“Š Generating trading signals...\")\n",
        "\n",
        "    # Initialize signal column\n",
        "    df['signal'] = 0\n",
        "\n",
        "    # Buy signal: positive 30-day momentum\n",
        "    df.loc[df['mom_30'] > 0, 'signal'] = 1\n",
        "\n",
        "    # Sell signal: non-positive 30-day momentum\n",
        "    df.loc[df['mom_30'] <= 0, 'signal'] = 0\n",
        "\n",
        "    # Calculate position changes (for detecting entry/exit points)\n",
        "    df['position'] = df['signal'].diff()\n",
        "\n",
        "    # Count signals\n",
        "    buy_signals = (df['signal'] == 1).sum()\n",
        "    sell_signals = (df['signal'] == 0).sum()\n",
        "\n",
        "    print(f\"âœ“ Signals generated:\")\n",
        "    print(f\"  - {buy_signals} buy periods\")\n",
        "    print(f\"  - {sell_signals} sell/hold periods\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "mr2GV0wUEHin"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# SECTION 5: BACKTESTING ENGINE\n",
        "# ================================================================================\n",
        "\n",
        "class MomentumBacktester:\n",
        "    \"\"\"\n",
        "    Backtesting engine for momentum trading strategies\n",
        "\n",
        "    Tracks portfolio state, executes trades, and calculates performance metrics\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, initial_capital=1000, capital_per_trade=100):\n",
        "        \"\"\"\n",
        "        Initialize backtester\n",
        "\n",
        "        Args:\n",
        "            data: DataFrame with price data and signals\n",
        "            initial_capital: Starting capital in dollars\n",
        "            capital_per_trade: Maximum capital to use per trade\n",
        "        \"\"\"\n",
        "        self.data = data.copy()\n",
        "        self.initial_capital = initial_capital\n",
        "        self.capital = initial_capital\n",
        "        self.capital_per_trade = capital_per_trade\n",
        "\n",
        "        # Portfolio state\n",
        "        self.position = 0  # Number of shares currently held\n",
        "        self.entry_price = 0  # Price at which current position was entered\n",
        "\n",
        "        # Trade tracking\n",
        "        self.trades = []  # List of all executed trades\n",
        "        self.equity_curve = []  # Portfolio value over time\n",
        "\n",
        "    def execute_backtest(self):\n",
        "        \"\"\"\n",
        "        Run the backtest simulation\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of performance metrics\n",
        "        \"\"\"\n",
        "        print(\"\\nðŸš€ Running backtest simulation...\")\n",
        "\n",
        "        trade_count = 0\n",
        "\n",
        "        for idx, row in self.data.iterrows():\n",
        "            current_price = row['adjclose']\n",
        "            signal = row['signal']\n",
        "\n",
        "            # Calculate current portfolio value\n",
        "            position_value = self.position * current_price\n",
        "            portfolio_value = self.capital + position_value\n",
        "\n",
        "            # Record equity curve point\n",
        "            self.equity_curve.append({\n",
        "                'date': idx,\n",
        "                'portfolio_value': portfolio_value,\n",
        "                'capital': self.capital,\n",
        "                'position': self.position,\n",
        "                'price': current_price\n",
        "            })\n",
        "\n",
        "            # ============ ENTRY LOGIC ============\n",
        "            if signal == 1 and self.position == 0:  # Buy signal and no position\n",
        "                # Calculate shares to buy\n",
        "                shares_to_buy = int(self.capital_per_trade / current_price)\n",
        "\n",
        "                if shares_to_buy > 0 and self.capital >= shares_to_buy * current_price:\n",
        "                    # Execute buy order\n",
        "                    cost = shares_to_buy * current_price\n",
        "                    self.position = shares_to_buy\n",
        "                    self.capital -= cost\n",
        "                    self.entry_price = current_price\n",
        "                    trade_count += 1\n",
        "\n",
        "                    self.trades.append({\n",
        "                        'date': idx,\n",
        "                        'type': 'BUY',\n",
        "                        'price': current_price,\n",
        "                        'shares': shares_to_buy,\n",
        "                        'cost': cost,\n",
        "                        'capital': self.capital\n",
        "                    })\n",
        "\n",
        "            # ============ EXIT LOGIC ============\n",
        "            elif signal == 0 and self.position > 0:  # Sell signal and holding position\n",
        "                # Execute sell order\n",
        "                proceeds = self.position * current_price\n",
        "                pnl = proceeds - (self.position * self.entry_price)\n",
        "                self.capital += proceeds\n",
        "                trade_count += 1\n",
        "\n",
        "                self.trades.append({\n",
        "                    'date': idx,\n",
        "                    'type': 'SELL',\n",
        "                    'price': current_price,\n",
        "                    'shares': self.position,\n",
        "                    'proceeds': proceeds,\n",
        "                    'pnl': pnl,\n",
        "                    'capital': self.capital\n",
        "                })\n",
        "\n",
        "                # Close position\n",
        "                self.position = 0\n",
        "                self.entry_price = 0\n",
        "\n",
        "        # ============ CLOSE ANY REMAINING POSITION ============\n",
        "        if self.position > 0:\n",
        "            final_price = self.data.iloc[-1]['adjclose']\n",
        "            proceeds = self.position * final_price\n",
        "            pnl = proceeds - (self.position * self.entry_price)\n",
        "            self.capital += proceeds\n",
        "            trade_count += 1\n",
        "\n",
        "            self.trades.append({\n",
        "                'date': self.data.index[-1],\n",
        "                'type': 'SELL (FINAL)',\n",
        "                'price': final_price,\n",
        "                'shares': self.position,\n",
        "                'proceeds': proceeds,\n",
        "                'pnl': pnl,\n",
        "                'capital': self.capital\n",
        "            })\n",
        "\n",
        "            self.position = 0\n",
        "\n",
        "        print(f\"âœ“ Backtest complete: {trade_count} trades executed\")\n",
        "\n",
        "        # Calculate and return performance metrics\n",
        "        return self.calculate_performance_metrics()\n",
        "\n",
        "    def calculate_performance_metrics(self):\n",
        "        \"\"\"\n",
        "        Calculate comprehensive performance metrics\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing all performance statistics\n",
        "        \"\"\"\n",
        "        print(\"\\nðŸ“ˆ Calculating performance metrics...\")\n",
        "\n",
        "        # Convert to DataFrames for easier analysis\n",
        "        equity_df = pd.DataFrame(self.equity_curve)\n",
        "        trades_df = pd.DataFrame(self.trades)\n",
        "\n",
        "        # ============ BASIC RETURNS ============\n",
        "        final_capital = self.capital\n",
        "        total_return = final_capital - self.initial_capital\n",
        "        pnl_percent = total_return / self.initial_capital\n",
        "\n",
        "        # ============ TRADE STATISTICS ============\n",
        "        if 'pnl' in trades_df.columns and len(trades_df) > 0:\n",
        "            profitable_trades = trades_df[trades_df['pnl'] > 0]\n",
        "            losing_trades = trades_df[trades_df['pnl'] < 0]\n",
        "\n",
        "            total_profit = profitable_trades['pnl'].sum() if len(profitable_trades) > 0 else 0\n",
        "            total_loss = abs(losing_trades['pnl'].sum()) if len(losing_trades) > 0 else 0\n",
        "            count_profit = len(profitable_trades)\n",
        "            count_loss = len(losing_trades)\n",
        "        else:\n",
        "            total_profit = 0\n",
        "            total_loss = 0\n",
        "            count_profit = 0\n",
        "            count_loss = 0\n",
        "\n",
        "        # ============ PORTFOLIO STATISTICS ============\n",
        "        portfolio_values = equity_df['portfolio_value'].values\n",
        "\n",
        "        # Daily returns\n",
        "        returns = np.diff(portfolio_values) / portfolio_values[:-1]\n",
        "\n",
        "        # Drawdown analysis\n",
        "        running_max = np.maximum.accumulate(portfolio_values)\n",
        "        drawdown_percent = (portfolio_values - running_max) / running_max\n",
        "        max_drawdown_dollars = abs(drawdown_percent.min()) * self.initial_capital\n",
        "\n",
        "        # ============ ANNUALIZED METRICS ============\n",
        "        trading_days = len(self.data)\n",
        "        years = trading_days / 252  # 252 trading days per year\n",
        "\n",
        "        annual_return = pnl_percent / years if years > 0 else 0\n",
        "        annual_vol = returns.std() * np.sqrt(252) if len(returns) > 0 else 0\n",
        "        sharpe_ratio = annual_return / annual_vol if annual_vol > 0 else 0\n",
        "\n",
        "        # ============ BENCHMARK COMPARISON ============\n",
        "        # Buy and hold return\n",
        "        benchmark_return = (self.data.iloc[-1]['adjclose'] - self.data.iloc[0]['adjclose']) / self.data.iloc[0]['adjclose']\n",
        "\n",
        "        # Score: excess return over benchmark\n",
        "        score = (pnl_percent - benchmark_return) / abs(benchmark_return) if benchmark_return != 0 else 0\n",
        "\n",
        "        # ============ COMPILE RESULTS ============\n",
        "        results = {\n",
        "            'instrument_names': ['AAPL'],\n",
        "            'instrument_stats': [{\n",
        "                'pnl': {'AAPL': pnl_percent},\n",
        "                'score': {'AAPL': score}\n",
        "            }],\n",
        "            'pnl': pnl_percent,\n",
        "            'trading_days': trading_days,\n",
        "            'annual_return': annual_return,\n",
        "            'annual_vol': annual_vol,\n",
        "            'sharpe_ratio': sharpe_ratio,\n",
        "            'score': score,\n",
        "            'capitalUsage': self.capital_per_trade,\n",
        "            'total_profit': total_profit,\n",
        "            'maxDrawdown': max_drawdown_dollars,\n",
        "            'maxPortfolioValue': portfolio_values.max(),\n",
        "            'total_loss': total_loss,\n",
        "            'variance': returns.var() if len(returns) > 0 else 0,\n",
        "            'capital': final_capital,\n",
        "            'count_profit': count_profit,\n",
        "            'portfolio_value': portfolio_values[-1],\n",
        "            'count_loss': count_loss\n",
        "        }\n",
        "\n",
        "        print(\"âœ“ Metrics calculated\")\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "sg1W4WRWEpT0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# SECTION 6: RESULTS DISPLAY\n",
        "# ================================================================================\n",
        "\n",
        "def display_results(results, backtester):\n",
        "    \"\"\"\n",
        "    Display backtest results in a formatted output\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary of performance metrics\n",
        "        backtester: MomentumBacktester instance\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BACKTEST RESULTS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Key performance metrics\n",
        "    print(\"\\nðŸ“Š PERFORMANCE METRICS:\")\n",
        "    print(f\"  Initial Capital:     ${backtester.initial_capital:,.2f}\")\n",
        "    print(f\"  Final Capital:       ${results['capital']:,.2f}\")\n",
        "    print(f\"  Total Return:        ${results['capital'] - backtester.initial_capital:,.2f}\")\n",
        "    print(f\"  Return %:            {results['pnl']*100:.2f}%\")\n",
        "    print(f\"  Annual Return:       {results['annual_return']*100:.2f}%\")\n",
        "    print(f\"  Sharpe Ratio:        {results['sharpe_ratio']:.4f}\")\n",
        "\n",
        "    # Risk metrics\n",
        "    print(\"\\nâš ï¸  RISK METRICS:\")\n",
        "    print(f\"  Max Drawdown:        ${results['maxDrawdown']:,.2f}\")\n",
        "    print(f\"  Annual Volatility:   {results['annual_vol']*100:.2f}%\")\n",
        "    print(f\"  Variance:            {results['variance']:.6f}\")\n",
        "\n",
        "    # Trading statistics\n",
        "    print(\"\\nðŸ“ˆ TRADING STATISTICS:\")\n",
        "    print(f\"  Total Trades:        {results['count_profit'] + results['count_loss']}\")\n",
        "    print(f\"  Winning Trades:      {results['count_profit']}\")\n",
        "    print(f\"  Losing Trades:       {results['count_loss']}\")\n",
        "\n",
        "    if (results['count_profit'] + results['count_loss']) > 0:\n",
        "        win_rate = results['count_profit'] / (results['count_profit'] + results['count_loss']) * 100\n",
        "        print(f\"  Win Rate:            {win_rate:.2f}%\")\n",
        "\n",
        "    print(f\"  Total Profit:        ${results['total_profit']:,.2f}\")\n",
        "    print(f\"  Total Loss:          ${results['total_loss']:,.2f}\")\n",
        "\n",
        "    # Additional info\n",
        "    print(\"\\nðŸ“… PERIOD:\")\n",
        "    print(f\"  Trading Days:        {results['trading_days']}\")\n",
        "    print(f\"  Years:               {results['trading_days']/252:.2f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "id": "x5VUHgtbEMhe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================================\n",
        "# SECTION 7: MAIN EXECUTION\n",
        "# ================================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function - orchestrates the entire backtesting pipeline\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"           MOMENTUM TRADING STRATEGY BACKTEST\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ========== STEP 1: DATA ACQUISITION ==========\n",
        "    df = download_stock_data(\n",
        "        symbol='AAPL',\n",
        "        start_date='2014-06-01',\n",
        "        end_date='2017-09-01'\n",
        "    )\n",
        "\n",
        "    # ========== STEP 2: FEATURE ENGINEERING ==========\n",
        "    df = engineer_features(df)\n",
        "\n",
        "    # ========== STEP 3: FILTER TO BACKTEST PERIOD ==========\n",
        "    # (Allow warmup period for indicators, then start backtest)\n",
        "    backtest_start = '2015-01-02'\n",
        "    backtest_end = '2017-08-31'\n",
        "    df = df.loc[backtest_start:backtest_end]\n",
        "\n",
        "    print(f\"\\nðŸ“… Backtest Period: {backtest_start} to {backtest_end}\")\n",
        "    print(f\"   Total Days: {len(df)}\")\n",
        "\n",
        "    # ========== STEP 4: GENERATE SIGNALS ==========\n",
        "    df = generate_trading_signals(df)\n",
        "\n",
        "    # ========== STEP 5: RUN BACKTEST ==========\n",
        "    backtester = MomentumBacktester(\n",
        "        data=df,\n",
        "        initial_capital=1000,\n",
        "        capital_per_trade=100\n",
        "    )\n",
        "\n",
        "    results = backtester.execute_backtest()\n",
        "\n",
        "    # ========== STEP 6: DISPLAY RESULTS ==========\n",
        "    display_results(results, backtester)\n",
        "\n",
        "    # ========== STEP 7: RETURN FULL RESULTS ==========\n",
        "    print(\"\\nðŸ“¦ Full Results Dictionary:\")\n",
        "    print(\"=\"*70)\n",
        "    print(results)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "pY54Gh1yEPD_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# SECTION 8: SCRIPT ENTRY POINT\n",
        "# ================================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NLjiHRxETnf",
        "outputId": "644e176e-64f5-49f6-bd8a-240c6a353992"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "           MOMENTUM TRADING STRATEGY BACKTEST\n",
            "======================================================================\n",
            "ðŸ“¥ Downloading AAPL data from 2014-06-01 to 2017-09-01...\n",
            "âœ“ Downloaded 821 trading days\n",
            "\n",
            "ðŸ”§ Engineering technical features...\n",
            "âœ“ Features calculated\n",
            "  - Removed 30 warmup rows (indicator initialization)\n",
            "  - 791 valid rows remaining\n",
            "\n",
            "ðŸ“… Backtest Period: 2015-01-02 to 2017-08-31\n",
            "   Total Days: 672\n",
            "\n",
            "ðŸ“Š Generating trading signals...\n",
            "âœ“ Signals generated:\n",
            "  - 406 buy periods\n",
            "  - 266 sell/hold periods\n",
            "\n",
            "ðŸš€ Running backtest simulation...\n",
            "âœ“ Backtest complete: 54 trades executed\n",
            "\n",
            "ðŸ“ˆ Calculating performance metrics...\n",
            "âœ“ Metrics calculated\n",
            "\n",
            "======================================================================\n",
            "BACKTEST RESULTS SUMMARY\n",
            "======================================================================\n",
            "\n",
            "ðŸ“Š PERFORMANCE METRICS:\n",
            "  Initial Capital:     $1,000.00\n",
            "  Final Capital:       $1,025.66\n",
            "  Total Return:        $25.66\n",
            "  Return %:            2.57%\n",
            "  Annual Return:       0.96%\n",
            "  Sharpe Ratio:        0.6853\n",
            "\n",
            "âš ï¸  RISK METRICS:\n",
            "  Max Drawdown:        $22.68\n",
            "  Annual Volatility:   1.40%\n",
            "  Variance:            0.000001\n",
            "\n",
            "ðŸ“ˆ TRADING STATISTICS:\n",
            "  Total Trades:        27\n",
            "  Winning Trades:      11\n",
            "  Losing Trades:       16\n",
            "  Win Rate:            40.74%\n",
            "  Total Profit:        $52.27\n",
            "  Total Loss:          $26.61\n",
            "\n",
            "ðŸ“… PERIOD:\n",
            "  Trading Days:        672\n",
            "  Years:               2.67\n",
            "\n",
            "======================================================================\n",
            "\n",
            "ðŸ“¦ Full Results Dictionary:\n",
            "======================================================================\n",
            "{'instrument_names': ['AAPL'], 'instrument_stats': [{'pnl': {'AAPL': np.float64(0.0256574649810791)}, 'score': {'AAPL': np.float64(-0.9556828096846225)}}], 'pnl': np.float64(0.0256574649810791), 'trading_days': 672, 'annual_return': np.float64(0.009621549367904663), 'annual_vol': np.float64(0.014039296043164048), 'sharpe_ratio': np.float64(0.6853299010379901), 'score': np.float64(-0.9556828096846225), 'capitalUsage': 100, 'total_profit': np.float64(52.26508903503418), 'maxDrawdown': np.float64(22.67526497956133), 'maxPortfolioValue': np.float64(1027.4500141143799), 'total_loss': np.float64(26.607624053955078), 'variance': np.float64(7.821501324904828e-07), 'capital': np.float64(1025.657464981079), 'count_profit': 11, 'portfolio_value': np.float64(1025.657464981079), 'count_loss': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. ML Trading Strategy: Classification with Rolling Cross-Validation (RAW)\n"
      ],
      "metadata": {
        "id": "nkjEv50nGBY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Real ML Trading Strategy: Random Forest with Rolling Cross-Validation\n",
        "With Overfitting Analysis (Train vs Test)\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. DATA ACQUISITION\n",
        "# ==============================================================================\n",
        "def download_stock_data(symbol='AAPL', start_date='2010-01-01', end_date='2023-01-01'):\n",
        "    print(f\"ðŸ“¥ Downloading {symbol}...\")\n",
        "    df = yf.download(symbol, start=start_date, end=end_date, progress=False, auto_adjust=False)\n",
        "\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.droplevel(1)\n",
        "    if df.index.tz is not None:\n",
        "        df.index = df.index.tz_localize(None)\n",
        "\n",
        "    df.columns = [c.replace(' ', '_').lower() for c in df.columns]\n",
        "\n",
        "    # Ensure 'adjclose' exists\n",
        "    if 'adj_close' in df.columns:\n",
        "        df['adjclose'] = df['adj_close']\n",
        "    elif 'close' in df.columns:\n",
        "        df['adjclose'] = df['close']\n",
        "\n",
        "    return df\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. FEATURE ENGINEERING (X) & TARGET CREATION (Y)\n",
        "# ==============================================================================\n",
        "def prepare_ml_data(df):\n",
        "    data = df.copy()\n",
        "\n",
        "    # --- FEATURES (X) ---\n",
        "    # 1. Momentum (Returns)\n",
        "    data['ret_1d'] = data['adjclose'].pct_change()\n",
        "    data['ret_5d'] = data['adjclose'].pct_change(5)\n",
        "\n",
        "    # 2. Volatility (Risk)\n",
        "    data['vol_20'] = data['ret_1d'].rolling(20).std()\n",
        "\n",
        "    # 3. Simple Moving Average Ratio (Trend)\n",
        "    data['ma_50'] = data['adjclose'].rolling(50).mean()\n",
        "    data['dist_to_ma'] = (data['adjclose'] / data['ma_50']) - 1\n",
        "\n",
        "    # 4. RSI\n",
        "    delta = data['adjclose'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    data['rsi'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # --- TARGET (Y) ---\n",
        "    data['target'] = (data['adjclose'].shift(-1) > data['adjclose']).astype(int)\n",
        "\n",
        "    data = data.dropna()\n",
        "    feature_cols = ['ret_1d', 'ret_5d', 'vol_20', 'dist_to_ma', 'rsi']\n",
        "\n",
        "    return data, feature_cols\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. BACKTESTING ENGINE (EXECUTION)\n",
        "# ==============================================================================\n",
        "class MLBacktester:\n",
        "    def __init__(self, data, predictions):\n",
        "        self.data = data.copy()\n",
        "        self.data['pred_signal'] = predictions\n",
        "        self.capital = 10000\n",
        "\n",
        "    def run(self):\n",
        "        # If signal is 1, we get the day's return. If 0, we get 0.\n",
        "        # shift(1) because prediction made today applies to tomorrow's return\n",
        "        self.data['strategy_ret'] = self.data['pred_signal'].shift(1) * self.data['ret_1d']\n",
        "        self.data['cum_ret'] = (1 + self.data['strategy_ret']).cumprod()\n",
        "        final_return = self.data['cum_ret'].iloc[-1] - 1\n",
        "        return final_return\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. ROLLING CROSS-VALIDATION WITH OVERFITTING CHECK\n",
        "# ==============================================================================\n",
        "def run_rolling_ml(df, feature_cols, train_months=24, test_months=6):\n",
        "\n",
        "    print(f\"\\nðŸ¤– TRAINING RANDOM FOREST (Rolling Window)\")\n",
        "    print(f\"   Features: {feature_cols}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    start_index = 0\n",
        "    train_size = train_months * 21\n",
        "    test_size = test_months * 21\n",
        "\n",
        "    # Initialize Model (max_depth=3 controls overfitting)\n",
        "    model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
        "\n",
        "    while start_index + train_size + test_size < len(df):\n",
        "\n",
        "        # --- 1. SPLITTING ---\n",
        "        train_data = df.iloc[start_index : start_index + train_size]\n",
        "        test_data = df.iloc[start_index + train_size : start_index + train_size + test_size]\n",
        "\n",
        "        if len(test_data) == 0: break\n",
        "\n",
        "        X_train = train_data[feature_cols]\n",
        "        y_train = train_data['target']\n",
        "\n",
        "        X_test = test_data[feature_cols]\n",
        "        y_test = test_data['target']\n",
        "\n",
        "        # --- 2. TRAINING ---\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # --- 3. OVERFITTING CHECK (TRAIN METRICS) ---\n",
        "        # How well did it memorize the \"Homework\"?\n",
        "        train_preds = model.predict(X_train)\n",
        "        train_acc = accuracy_score(y_train, train_preds)\n",
        "\n",
        "        # Calculate Train PnL (Theoretical)\n",
        "        train_tester = MLBacktester(train_data, train_preds)\n",
        "        train_pnl = train_tester.run()\n",
        "\n",
        "        # --- 4. REALITY CHECK (TEST METRICS) ---\n",
        "        # How well did it do on the \"Final Exam\"?\n",
        "        test_preds = model.predict(X_test)\n",
        "        test_acc = accuracy_score(y_test, test_preds)\n",
        "\n",
        "        # Calculate Test PnL (Real)\n",
        "        test_tester = MLBacktester(test_data, test_preds)\n",
        "        test_pnl = test_tester.run()\n",
        "\n",
        "        # Gap Analysis\n",
        "        gap_acc = train_acc - test_acc\n",
        "\n",
        "        # Regime Detection\n",
        "        vol = test_data['ret_1d'].std() * np.sqrt(252)\n",
        "        if vol > 0.30:\n",
        "            regime_str = \"High Volatility (Panic)\"\n",
        "        elif test_data['adjclose'].iloc[-1] > test_data['adjclose'].iloc[0]:\n",
        "            regime_str = \"Bull Market (Calm Up)\"\n",
        "        else:\n",
        "            regime_str = \"Bear Market (Calm Down)\"\n",
        "\n",
        "        # Store Results\n",
        "        results.append({\n",
        "            'Period_Start': test_data.index[0],\n",
        "            'Period_End': test_data.index[-1],\n",
        "            'Regime': regime_str,\n",
        "            'Train_Acc': train_acc,\n",
        "            'Test_Acc': test_acc,\n",
        "            'Gap_Acc': gap_acc,\n",
        "            'Train_PnL': train_pnl,\n",
        "            'Test_PnL': test_pnl\n",
        "        })\n",
        "\n",
        "        # Slide forward\n",
        "        start_index += test_size\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. MAIN EXECUTION\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Get Data\n",
        "    raw_df = download_stock_data('AAPL', '2010-01-01', '2023-01-01')\n",
        "\n",
        "    # 2. Prepare Features\n",
        "    ml_df, features = prepare_ml_data(raw_df)\n",
        "\n",
        "    # 3. Run ML\n",
        "    results_df = run_rolling_ml(ml_df, features, train_months=36, test_months=6)\n",
        "\n",
        "    # 4. Display Results (Formatted as requested)\n",
        "\n",
        "    # Set Pandas to display percentages nicely\n",
        "    pd.options.display.float_format = '{:,.2%}'.format\n",
        "\n",
        "    # Select columns for the detailed view\n",
        "    display_cols = ['Period_Start', 'Period_End', 'Regime', 'Train_Acc', 'Test_Acc', 'Gap_Acc', 'Train_PnL', 'Test_PnL']\n",
        "\n",
        "    print(\"\\nðŸ“‰ PERIOD-BY-PERIOD RESULTS (Train vs Test)\")\n",
        "    print(\"=\"*120)\n",
        "    print(results_df[display_cols].to_string(index=False))\n",
        "\n",
        "    print(\"\\nðŸ“Š ML RESULTS SUMMARY\")\n",
        "    print(f\"Average PnL per period:   {results_df['Test_PnL'].mean():.2%}\")\n",
        "    print(f\"Average Model Accuracy:   {results_df['Test_Acc'].mean():.2%}\")\n",
        "    print(f\"Win Rate (Profitable Periods): {len(results_df[results_df['Test_PnL']>0]) / len(results_df):.0%}\")\n",
        "\n",
        "    print(\"\\nðŸ“Š OVERFITTING SUMMARY\")\n",
        "    print(f\"Average Train Acc: {results_df['Train_Acc'].mean():.2%}\")\n",
        "    print(f\"Average Test Acc:  {results_df['Test_Acc'].mean():.2%}\")\n",
        "    print(f\"Average Gap:       {results_df['Gap_Acc'].mean():.2%}\")\n",
        "\n",
        "    if results_df['Gap_Acc'].mean() > 0.10:\n",
        "        print(\"âš ï¸ WARNING: High Overfitting (>10% Gap). Consider reducing max_depth or features.\")\n",
        "    else:\n",
        "        print(\"âœ… Model looks stable (Gap < 10%).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY2goJ4jEaBO",
        "outputId": "6b9be779-71d3-4d9b-f2cd-d5e0a33ae549"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Downloading AAPL...\n",
            "\n",
            "ðŸ¤– TRAINING RANDOM FOREST (Rolling Window)\n",
            "   Features: ['ret_1d', 'ret_5d', 'vol_20', 'dist_to_ma', 'rsi']\n",
            "================================================================================\n",
            "\n",
            "ðŸ“‰ PERIOD-BY-PERIOD RESULTS (Train vs Test)\n",
            "========================================================================================================================\n",
            "Period_Start Period_End                  Regime  Train_Acc  Test_Acc  Gap_Acc  Train_PnL  Test_PnL\n",
            "  2013-03-18 2013-09-13   Bull Market (Calm Up)     63.89%    50.79%   13.10%    717.88%    15.14%\n",
            "  2013-09-16 2014-03-17   Bull Market (Calm Up)     61.90%    46.03%   15.87%    543.30%     0.50%\n",
            "  2014-03-18 2014-09-15   Bull Market (Calm Up)     66.80%    49.21%   17.59%    677.75%    20.82%\n",
            "  2014-09-16 2015-03-17   Bull Market (Calm Up)     65.87%    53.97%   11.90%    402.83%    17.63%\n",
            "  2015-03-18 2015-09-15 Bear Market (Calm Down)     65.74%    50.79%   14.95%    328.70%     1.66%\n",
            "  2015-09-16 2016-03-16 Bear Market (Calm Down)     67.33%    46.83%   20.50%    332.64%   -12.88%\n",
            "  2016-03-17 2016-09-14   Bull Market (Calm Up)     64.55%    47.62%   16.93%    231.43%    -5.90%\n",
            "  2016-09-15 2017-03-16   Bull Market (Calm Up)     67.06%    53.97%   13.10%    314.11%    13.29%\n",
            "  2017-03-17 2017-09-14   Bull Market (Calm Up)     66.53%    48.41%   18.12%    366.79%     1.30%\n",
            "  2017-09-15 2018-03-16   Bull Market (Calm Up)     66.14%    46.83%   19.31%    355.01%     6.97%\n",
            "  2018-03-19 2018-09-14   Bull Market (Calm Up)     68.92%    48.41%   20.50%    405.77%    12.12%\n",
            "  2018-09-17 2019-03-19 High Volatility (Panic)     66.93%    53.97%   12.96%    532.00%   -15.32%\n",
            "  2019-03-20 2019-09-17   Bull Market (Calm Up)     65.08%    51.59%   13.49%    423.83%    11.82%\n",
            "  2019-09-18 2020-03-18 High Volatility (Panic)     65.61%    56.35%    9.26%    435.99%    39.78%\n",
            "  2020-03-19 2020-09-16 High Volatility (Panic)     64.02%    59.52%    4.50%    558.45%    91.52%\n",
            "  2020-09-17 2021-03-18 High Volatility (Panic)     62.96%    46.83%   16.14%    721.13%     5.51%\n",
            "  2021-03-19 2021-09-16   Bull Market (Calm Up)     62.57%    57.14%    5.42%    762.08%    26.96%\n",
            "  2021-09-17 2022-03-17   Bull Market (Calm Up)     62.57%    49.21%   13.36%    935.17%    -2.66%\n",
            "  2022-03-18 2022-09-16 High Volatility (Panic)     62.57%    51.59%   10.98%  1,027.03%    -2.90%\n",
            "\n",
            "ðŸ“Š ML RESULTS SUMMARY\n",
            "Average PnL per period:   11.86%\n",
            "Average Model Accuracy:   51.00%\n",
            "Win Rate (Profitable Periods): 74%\n",
            "\n",
            "ðŸ“Š OVERFITTING SUMMARY\n",
            "Average Train Acc: 65.11%\n",
            "Average Test Acc:  51.00%\n",
            "Average Gap:       14.10%\n",
            "âš ï¸ WARNING: High Overfitting (>10% Gap). Consider reducing max_depth or features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. ML Trading Strategy: Classification with Rolling Cross-Validation (New Features + Normalized)"
      ],
      "metadata": {
        "id": "w9-zLhJvG1Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Advanced ML Classification: Overfitting Analysis (Train vs Test)\n",
        "Features: Hurst, MA Crossover, RSI, Correlation Filter\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. HELPER: HURST EXPONENT (Numpy Optimized)\n",
        "# ==============================================================================\n",
        "def get_hurst_exponent(time_series):\n",
        "    lags = range(2, 20)\n",
        "    tau = []\n",
        "    for lag in lags:\n",
        "        if len(time_series) > lag:\n",
        "            diff = np.subtract(time_series[lag:], time_series[:-lag])\n",
        "            tau.append(np.sqrt(np.std(diff)))\n",
        "        else:\n",
        "            return 0.5\n",
        "    try:\n",
        "        m = np.polyfit(np.log(lags), np.log(tau), 1)\n",
        "        return m[0] * 2.0\n",
        "    except:\n",
        "        return 0.5\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. FEATURE ENGINEERING\n",
        "# ==============================================================================\n",
        "def prepare_features(df):\n",
        "    print(\"ðŸ›  Generating Technical Features...\")\n",
        "    data = df.copy()\n",
        "\n",
        "    # Classic Momentum\n",
        "    data['ma_15'] = data['adjclose'].rolling(window=15).mean()\n",
        "    data['ma_150'] = data['adjclose'].rolling(window=150).mean()\n",
        "    data['ma_spread'] = (data['ma_15'] - data['ma_150']) / data['ma_150']\n",
        "\n",
        "    # MH Indicator (Hurst)\n",
        "    log_ret = np.log(data['adjclose'] / data['adjclose'].shift(1))\n",
        "    data['h16'] = log_ret.rolling(window=16).apply(get_hurst_exponent, raw=True)\n",
        "    data['h32'] = log_ret.rolling(window=32).apply(get_hurst_exponent, raw=True)\n",
        "    data['mh_diff'] = data['h32'] - data['h16']\n",
        "\n",
        "    # RSI\n",
        "    delta = data['adjclose'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    data['rsi'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Standard\n",
        "    data['ret_1d'] = data['adjclose'].pct_change()\n",
        "    data['vol_20'] = data['ret_1d'].rolling(20).std()\n",
        "\n",
        "    # Target\n",
        "    data['target'] = (data['adjclose'].shift(-1) > data['adjclose']).astype(int)\n",
        "\n",
        "    data = data.dropna()\n",
        "    return data\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. CORRELATION FILTER\n",
        "# ==============================================================================\n",
        "def remove_correlated_features(df, feature_cols, threshold=0.7):\n",
        "    print(\"\\nðŸ” CHECKING FEATURE CORRELATION...\")\n",
        "    df_feat = df[feature_cols]\n",
        "    corr_matrix = df_feat.corr().abs()\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "    return [f for f in feature_cols if f not in to_drop]\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. REGIME DETECTION\n",
        "# ==============================================================================\n",
        "def detect_regime(data_slice):\n",
        "    vol = data_slice['ret_1d'].std() * np.sqrt(252)\n",
        "    if vol > 0.30:\n",
        "        return \"High Volatility (Panic)\"\n",
        "    elif data_slice['adjclose'].iloc[-1] > data_slice['adjclose'].iloc[0]:\n",
        "        return \"Bull Market (Calm Up)\"\n",
        "    else:\n",
        "        return \"Bear Market (Calm Down)\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. ROLLING CLASSIFICATION (With Train vs Test Analysis)\n",
        "# ==============================================================================\n",
        "def run_rolling_classification(df, feature_cols):\n",
        "\n",
        "    print(f\"\\nðŸš€ STARTING ROLLING BACKTEST (Checking Overfitting)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    train_months = 24\n",
        "    test_months = 6\n",
        "    train_size = train_months * 21\n",
        "    test_size = test_months * 21\n",
        "\n",
        "    results = []\n",
        "    model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
        "\n",
        "    start_index = 0\n",
        "    while start_index + train_size + test_size < len(df):\n",
        "\n",
        "        # 1. SPLIT\n",
        "        train_data = df.iloc[start_index : start_index + train_size]\n",
        "        test_data = df.iloc[start_index + train_size : start_index + train_size + test_size]\n",
        "\n",
        "        if len(test_data) == 0: break\n",
        "\n",
        "        # 2. NORMALIZE\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(train_data[feature_cols])\n",
        "        X_test = scaler.transform(test_data[feature_cols])\n",
        "\n",
        "        y_train = train_data['target']\n",
        "        y_test = test_data['target']\n",
        "\n",
        "        # 3. TRAIN\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # 4. PREDICT & MEASURE (TRAIN SET - The \"Homework\")\n",
        "        train_preds = model.predict(X_train)\n",
        "        train_acc = accuracy_score(y_train, train_preds)\n",
        "\n",
        "        # Calculate Train PnL (How well it traded the history)\n",
        "        train_ret = train_preds * train_data['ret_1d'].values\n",
        "        pnl_train = (1 + train_ret).cumprod()[-1] - 1\n",
        "\n",
        "        # 5. PREDICT & MEASURE (TEST SET - The \"Final Exam\")\n",
        "        test_preds = model.predict(X_test)\n",
        "        test_acc = accuracy_score(y_test, test_preds)\n",
        "\n",
        "        # Calculate Test PnL (Real performance)\n",
        "        test_ret = test_preds * test_data['ret_1d'].values\n",
        "        pnl_test = (1 + test_ret).cumprod()[-1] - 1\n",
        "\n",
        "        # 6. CALCULATE GAP\n",
        "        acc_gap = train_acc - test_acc\n",
        "\n",
        "        regime = detect_regime(test_data)\n",
        "\n",
        "        results.append({\n",
        "            'Period_Start': test_data.index[0],\n",
        "            'Period_End': test_data.index[-1],\n",
        "            'Regime': regime,\n",
        "            'Train_Acc': train_acc,\n",
        "            'Test_Acc': test_acc,\n",
        "            'Gap_Acc': acc_gap,  # Important: High Gap = Overfitting\n",
        "            'Train_PnL': pnl_train,\n",
        "            'Test_PnL': pnl_test\n",
        "        })\n",
        "\n",
        "        start_index += test_size\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. MAIN EXECUTION\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 1. Data\n",
        "    print(\"ðŸ“¥ Downloading Data...\")\n",
        "    raw_df = yf.download('AAPL', start='2010-01-01', end='2024-01-01', progress=False, auto_adjust=False)\n",
        "    if isinstance(raw_df.columns, pd.MultiIndex): raw_df.columns = raw_df.columns.droplevel(1)\n",
        "    raw_df.columns = [c.lower() for c in raw_df.columns]\n",
        "    raw_df['adjclose'] = raw_df['adj close'] if 'adj close' in raw_df.columns else raw_df['close']\n",
        "\n",
        "    # 2. Features\n",
        "    df = prepare_features(raw_df)\n",
        "    features = ['ma_spread', 'mh_diff', 'h16', 'h32', 'vol_20', 'ret_1d', 'rsi']\n",
        "\n",
        "    # 3. Filter\n",
        "    final_features = remove_correlated_features(df, features, threshold=0.7)\n",
        "\n",
        "    # 4. Run Backtest\n",
        "    results_df = run_rolling_classification(df, final_features)\n",
        "\n",
        "    # ==========================================================================\n",
        "    # DISPLAY RESULTS\n",
        "    # ==========================================================================\n",
        "\n",
        "    # Formatting for cleaner display\n",
        "    display_cols = ['Period_Start', 'Period_End', 'Regime', 'Train_Acc', 'Test_Acc', 'Gap_Acc', 'Train_PnL', 'Test_PnL']\n",
        "\n",
        "    print(\"\\nðŸ“‰ PERIOD-BY-PERIOD RESULTS (Train vs Test)\")\n",
        "    print(\"=\"*120)\n",
        "    # Using formatters to make percentages look nice\n",
        "    pd.options.display.float_format = '{:,.2%}'.format\n",
        "    print(results_df[display_cols].head(5).to_string(index=False))\n",
        "    print(\"\\n...\\n\")\n",
        "    print(results_df[display_cols].tail(5).to_string(index=False))\n",
        "\n",
        "    print(\"\\nðŸ“Š ML RESULTS SUMMARY\")\n",
        "    print(f\"Average PnL per period:   {results_df['Test_PnL'].mean():.2%}\")\n",
        "    print(f\"Average Model Accuracy:   {results_df['Test_Acc'].mean():.2%}\")\n",
        "\n",
        "    # Calculate Win Rate\n",
        "    win_rate = (results_df['Test_PnL'] > 0).sum() / len(results_df)\n",
        "    print(f\"Win Rate (Profitable Periods): {win_rate:.0%}\")\n",
        "\n",
        "    print(\"\\nðŸ“Š OVERFITTING SUMMARY\")\n",
        "    print(f\"Average Train Acc: {results_df['Train_Acc'].mean():.2%}\")\n",
        "    print(f\"Average Test Acc:  {results_df['Test_Acc'].mean():.2%}\")\n",
        "    print(f\"Average Gap:       {results_df['Gap_Acc'].mean():.2%}\")\n",
        "\n",
        "    if results_df['Gap_Acc'].mean() > 0.10:\n",
        "        print(\"âš ï¸ WARNING: High Overfitting (>10% Gap). Consider reducing max_depth or features.\")\n",
        "    else:\n",
        "        print(\"âœ… Model looks stable (Gap < 10%).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrhDirQ6rIt6",
        "outputId": "c603e995-87c4-4f24-e1a6-8605a2a6beeb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Downloading Data...\n",
            "ðŸ›  Generating Technical Features...\n",
            "\n",
            "ðŸ” CHECKING FEATURE CORRELATION...\n",
            "\n",
            "ðŸš€ STARTING ROLLING BACKTEST (Checking Overfitting)\n",
            "================================================================================\n",
            "\n",
            "ðŸ“‰ PERIOD-BY-PERIOD RESULTS (Train vs Test)\n",
            "========================================================================================================================\n",
            "Period_Start Period_End                  Regime  Train_Acc  Test_Acc  Gap_Acc  Train_PnL  Test_PnL\n",
            "  2012-08-06 2013-02-06 High Volatility (Panic)     64.88%    46.83%   18.06%    205.95%   -25.43%\n",
            "  2013-02-07 2013-08-07 Bear Market (Calm Down)     68.85%    50.00%   18.85%     59.17%   -15.77%\n",
            "  2013-08-08 2014-02-06   Bull Market (Calm Up)     68.25%    52.38%   15.87%     29.82%    -4.91%\n",
            "  2014-02-07 2014-08-07   Bull Market (Calm Up)     67.06%    50.00%   17.06%    -29.29%    -7.39%\n",
            "  2014-08-08 2015-02-06   Bull Market (Calm Up)     68.25%    46.03%   22.22%    -75.82%   -29.87%\n",
            "\n",
            "...\n",
            "\n",
            "Period_Start Period_End                  Regime  Train_Acc  Test_Acc  Gap_Acc  Train_PnL  Test_PnL\n",
            "  2021-02-10 2021-08-10   Bull Market (Calm Up)     63.49%    50.79%   12.70%    -19.85%     7.88%\n",
            "  2021-08-11 2022-02-08   Bull Market (Calm Up)     63.69%    52.38%   11.31%    -56.00%     5.37%\n",
            "  2022-02-09 2022-08-10 High Volatility (Panic)     68.25%    57.94%   10.32%    -82.17%   -48.60%\n",
            "  2022-08-11 2023-02-09 High Volatility (Panic)     69.84%    45.24%   24.60%    -54.95%   -45.99%\n",
            "  2023-02-10 2023-08-11   Bull Market (Calm Up)     71.83%    49.21%   22.62%      2.67%     9.74%\n",
            "\n",
            "ðŸ“Š ML RESULTS SUMMARY\n",
            "Average PnL per period:   -6.10%\n",
            "Average Model Accuracy:   49.68%\n",
            "Win Rate (Profitable Periods): 36%\n",
            "\n",
            "ðŸ“Š OVERFITTING SUMMARY\n",
            "Average Train Acc: 68.53%\n",
            "Average Test Acc:  49.68%\n",
            "Average Gap:       18.86%\n",
            "âš ï¸ WARNING: High Overfitting (>10% Gap). Consider reducing max_depth or features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. ML Trading Strategy: Regression with Rolling Cross-Validation (RAW)"
      ],
      "metadata": {
        "id": "Zl1UMoMLHDHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Full ML Framework: Rolling CV, Model Selection, RMSE, PnL, & Regimes\n",
        "With Overfitting Analysis & Win Rate per Model\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 1: DATA ACQUISITION\n",
        "# ==============================================================================\n",
        "def get_data(symbol='AAPL'):\n",
        "    print(f\"ðŸ“¥ Downloading data for {symbol}...\")\n",
        "    df = yf.download(symbol, start='2010-01-01', end='2023-01-01', progress=False, auto_adjust=False)\n",
        "\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.droplevel(1)\n",
        "\n",
        "    # Standardize column names\n",
        "    df.columns = [c.lower() for c in df.columns]\n",
        "\n",
        "    # Use Adjusted Close if available, else Close\n",
        "    col = 'adj close' if 'adj close' in df.columns else 'close'\n",
        "    df['price'] = df[col]\n",
        "    return df[['price']]\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: FEATURE ENGINEERING\n",
        "# ==============================================================================\n",
        "def prepare_features(df):\n",
        "    data = df.copy()\n",
        "\n",
        "    # --- Features (X) ---\n",
        "    # 1. Momentum\n",
        "    data['ret_1d'] = data['price'].pct_change()\n",
        "    data['ret_5d'] = data['price'].pct_change(5)\n",
        "\n",
        "    # 2. Volatility\n",
        "    data['vol_20'] = data['ret_1d'].rolling(20).std()\n",
        "\n",
        "    # 3. Trend (MA Ratio)\n",
        "    data['ma_50_ratio'] = (data['price'] / data['price'].rolling(50).mean()) - 1\n",
        "\n",
        "    # --- Target (Y) ---\n",
        "    # Predict EXACT return of tomorrow\n",
        "    data['target'] = data['ret_1d'].shift(-1)\n",
        "\n",
        "    data = data.dropna()\n",
        "    return data\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: REGIME DETECTION\n",
        "# ==============================================================================\n",
        "def detect_regime(data_slice):\n",
        "    vol = data_slice['ret_1d'].std() * np.sqrt(252)\n",
        "\n",
        "    if vol > 0.30:\n",
        "        return \"High Volatility (Panic)\"\n",
        "    elif data_slice['price'].iloc[-1] > data_slice['price'].iloc[0]:\n",
        "        return \"Bull Market (Calm Up)\"\n",
        "    else:\n",
        "        return \"Bear Market (Calm Down)\"\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: ROLLING CV & MODEL SELECTION\n",
        "# ==============================================================================\n",
        "def run_full_analysis(df, models_to_test):\n",
        "\n",
        "    # Define features\n",
        "    features = ['ret_1d', 'ret_5d', 'vol_20', 'ma_50_ratio']\n",
        "\n",
        "    # Rolling Window Settings\n",
        "    train_months = 24\n",
        "    test_months = 6\n",
        "    train_size = train_months * 21\n",
        "    test_size = test_months * 21\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # --- LOOP: Rolling Time Windows ---\n",
        "    start_index = 0\n",
        "    while start_index + train_size + test_size < len(df):\n",
        "\n",
        "        # 1. SPLIT TIME\n",
        "        train_data = df.iloc[start_index : start_index + train_size]\n",
        "        test_data = df.iloc[start_index + train_size : start_index + train_size + test_size]\n",
        "\n",
        "        if len(test_data) == 0: break\n",
        "\n",
        "        # 2. CONTEXT\n",
        "        current_regime = detect_regime(test_data)\n",
        "\n",
        "        # 3. LOOP MODELS\n",
        "        for model_name, model_obj in models_to_test.items():\n",
        "\n",
        "            # A. TRAIN\n",
        "            X_train = train_data[features]\n",
        "            y_train = train_data['target']\n",
        "            model_obj.fit(X_train, y_train)\n",
        "\n",
        "            # Metrics (In-Sample)\n",
        "            pred_train = model_obj.predict(X_train)\n",
        "            rmse_train = np.sqrt(mean_squared_error(y_train, pred_train))\n",
        "\n",
        "            sig_train = np.where(pred_train > 0, 1, 0)\n",
        "            ret_train = sig_train * y_train\n",
        "            pnl_train = (1 + ret_train).cumprod().iloc[-1] - 1\n",
        "\n",
        "            # B. TEST\n",
        "            X_test = test_data[features]\n",
        "            y_test = test_data['target']\n",
        "\n",
        "            pred_test = model_obj.predict(X_test)\n",
        "\n",
        "            # Metrics (Out-of-Sample)\n",
        "            rmse_test = np.sqrt(mean_squared_error(y_test, pred_test))\n",
        "\n",
        "            sig_test = np.where(pred_test > 0, 1, 0)\n",
        "            ret_test = sig_test * y_test\n",
        "            pnl_test = (1 + ret_test).cumprod().iloc[-1] - 1\n",
        "\n",
        "            # Gap\n",
        "            rmse_gap = rmse_test - rmse_train\n",
        "\n",
        "            # Store\n",
        "            all_results.append({\n",
        "                'Period_Start': test_data.index[0],\n",
        "                'Period_End': test_data.index[-1],\n",
        "                'Model': model_name,\n",
        "                'Regime': current_regime,\n",
        "                'Train_RMSE': rmse_train,\n",
        "                'Test_RMSE': rmse_test,\n",
        "                'RMSE_Gap': rmse_gap,\n",
        "                'Train_PnL': pnl_train,\n",
        "                'Test_PnL': pnl_test\n",
        "            })\n",
        "\n",
        "        # Slide Window\n",
        "        start_index += test_size\n",
        "\n",
        "    # Add Year\n",
        "    results_df = pd.DataFrame(all_results)\n",
        "    results_df['Year'] = results_df['Period_End'].dt.year\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 5: MAIN EXECUTION\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 1. Prepare Data\n",
        "    raw_df = get_data('AAPL')\n",
        "    df = prepare_features(raw_df)\n",
        "\n",
        "    # 2. Define Models\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Random Forest': RandomForestRegressor(n_estimators=50, max_depth=3, random_state=42)\n",
        "    }\n",
        "\n",
        "    print(\"\\nðŸš€ STARTING ROLLING BACKTEST...\")\n",
        "    results_df = run_full_analysis(df, models)\n",
        "\n",
        "    # ==========================================================================\n",
        "    # STEP 6: DISPLAY RESULTS\n",
        "    # ==========================================================================\n",
        "\n",
        "    # Formatting\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.width', 1000)\n",
        "    pd.options.display.float_format = '{:.6f}'.format\n",
        "\n",
        "    # 1. Detailed Table\n",
        "    print(\"\\nðŸ“‰ PERIOD-BY-PERIOD RESULTS (Sample)\")\n",
        "    print(\"=\"*120)\n",
        "    cols = ['Period_Start', 'Period_End', 'Model', 'Regime', 'Train_RMSE', 'Test_RMSE', 'RMSE_Gap', 'Train_PnL', 'Test_PnL', 'Year']\n",
        "    print(results_df[cols].head(10).to_string(index=False))\n",
        "    print(\"\\n...\\n\")\n",
        "    print(results_df[cols].tail(6).to_string(index=False))\n",
        "\n",
        "    # 2. Model Stats Summary\n",
        "    print(\"\\nðŸ“Š REGRESSION SUMMARY (Average)\")\n",
        "    summary = results_df.groupby('Model')[['Train_RMSE', 'Test_RMSE', 'RMSE_Gap', 'Train_PnL', 'Test_PnL']].mean()\n",
        "    print(summary)\n",
        "\n",
        "    # 3. WIN RATE ANALYSIS (PER MODEL) - THE NEW PART\n",
        "    print(\"\\nðŸŽ¯ WIN RATE ANALYSIS (Per Model)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for model in results_df['Model'].unique():\n",
        "        # Filter for the specific model\n",
        "        model_data = results_df[results_df['Model'] == model]\n",
        "\n",
        "        # Calculate Wins (Where Test PnL > 0)\n",
        "        total_periods = len(model_data)\n",
        "        winning_periods = (model_data['Test_PnL'] > 0).sum()\n",
        "\n",
        "        # Calculate Percentage\n",
        "        if total_periods > 0:\n",
        "            win_rate = winning_periods / total_periods\n",
        "        else:\n",
        "            win_rate = 0.0\n",
        "\n",
        "        print(f\"   {model:<20}: {win_rate:.1%} ({winning_periods}/{total_periods} periods profitable)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb7SMcrET6El",
        "outputId": "e953cbab-8921-4180-8901-21de8095c25e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Downloading data for AAPL...\n",
            "\n",
            "ðŸš€ STARTING ROLLING BACKTEST...\n",
            "\n",
            "ðŸ“‰ PERIOD-BY-PERIOD RESULTS (Sample)\n",
            "========================================================================================================================\n",
            "Period_Start Period_End             Model                  Regime  Train_RMSE  Test_RMSE  RMSE_Gap  Train_PnL  Test_PnL  Year\n",
            "  2012-03-14 2012-09-11 Linear Regression   Bull Market (Calm Up)    0.016400   0.017639  0.001239   1.827783  0.144550  2012\n",
            "  2012-03-14 2012-09-11     Random Forest   Bull Market (Calm Up)    0.015067   0.017355  0.002288   4.662402  0.184748  2012\n",
            "  2012-09-12 2013-03-15 Linear Regression High Volatility (Panic)    0.016177   0.023174  0.006997   1.626431 -0.288746  2013\n",
            "  2012-09-12 2013-03-15     Random Forest High Volatility (Panic)    0.014310   0.026255  0.011945   3.579226 -0.052388  2013\n",
            "  2013-03-18 2013-09-13 Linear Regression   Bull Market (Calm Up)    0.018775   0.016835 -0.001940   0.478269 -0.126387  2013\n",
            "  2013-03-18 2013-09-13     Random Forest   Bull Market (Calm Up)    0.016897   0.017861  0.000964   3.363598 -0.070813  2013\n",
            "  2013-09-16 2014-03-17 Linear Regression   Bull Market (Calm Up)    0.018715   0.014398 -0.004317   0.470807  0.090690  2014\n",
            "  2013-09-16 2014-03-17     Random Forest   Bull Market (Calm Up)    0.017251   0.015150 -0.002101   2.613353  0.080445  2014\n",
            "  2014-03-18 2014-09-15 Linear Regression   Bull Market (Calm Up)    0.018142   0.012893 -0.005249   0.132613  0.237088  2014\n",
            "  2014-03-18 2014-09-15     Random Forest   Bull Market (Calm Up)    0.016812   0.013114 -0.003697   2.833800  0.171022  2014\n",
            "\n",
            "...\n",
            "\n",
            "Period_Start Period_End             Model                  Regime  Train_RMSE  Test_RMSE  RMSE_Gap  Train_PnL  Test_PnL  Year\n",
            "  2021-03-19 2021-09-16 Linear Regression   Bull Market (Calm Up)    0.023345   0.013074 -0.010271   2.681835  0.294415  2021\n",
            "  2021-03-19 2021-09-16     Random Forest   Bull Market (Calm Up)    0.021576   0.013121 -0.008455   4.275215  0.221163  2021\n",
            "  2021-09-17 2022-03-17 Linear Regression   Bull Market (Calm Up)    0.022736   0.018168 -0.004568   2.889694  0.030287  2022\n",
            "  2021-09-17 2022-03-17     Random Forest   Bull Market (Calm Up)    0.020890   0.017303 -0.003587   4.117109  0.102636  2022\n",
            "  2022-03-18 2022-09-16 Linear Regression High Volatility (Panic)    0.020542   0.022211  0.001669   1.908231  0.006331  2022\n",
            "  2022-03-18 2022-09-16     Random Forest High Volatility (Panic)    0.019330   0.022257  0.002927   2.902300  0.088730  2022\n",
            "\n",
            "ðŸ“Š REGRESSION SUMMARY (Average)\n",
            "                   Train_RMSE  Test_RMSE  RMSE_Gap  Train_PnL  Test_PnL\n",
            "Model                                                                  \n",
            "Linear Regression    0.017348   0.017755  0.000406   1.007080  0.066098\n",
            "Random Forest        0.015993   0.018249  0.002257   2.819160  0.104426\n",
            "\n",
            "ðŸŽ¯ WIN RATE ANALYSIS (Per Model)\n",
            "============================================================\n",
            "   Linear Regression   : 71.4% (15/21 periods profitable)\n",
            "   Random Forest       : 81.0% (17/21 periods profitable)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. ML Trading Strategy: Regressions with Rolling Cross-Validation (New Features + Normalized)"
      ],
      "metadata": {
        "id": "VpPlB9JtHiaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. HELPER & 2. FEATURES (Same as above)\n",
        "# ==============================================================================\n",
        "def get_hurst_exponent(time_series):\n",
        "    lags = range(2, 20)\n",
        "    tau = []\n",
        "    for lag in lags:\n",
        "        if len(time_series) > lag:\n",
        "            diff = np.subtract(time_series[lag:], time_series[:-lag])\n",
        "            tau.append(np.sqrt(np.std(diff)))\n",
        "        else:\n",
        "            return 0.5\n",
        "    try:\n",
        "        m = np.polyfit(np.log(lags), np.log(tau), 1)\n",
        "        return m[0] * 2.0\n",
        "    except:\n",
        "        return 0.5\n",
        "\n",
        "def prepare_features(df):\n",
        "    print(\"ðŸ›  Generating Technical Features...\")\n",
        "    data = df.copy()\n",
        "    data['ma_15'] = data['adjclose'].rolling(window=15).mean()\n",
        "    data['ma_150'] = data['adjclose'].rolling(window=150).mean()\n",
        "    data['ma_spread'] = (data['ma_15'] - data['ma_150']) / data['ma_150']\n",
        "\n",
        "    log_ret = np.log(data['adjclose'] / data['adjclose'].shift(1))\n",
        "    data['h16'] = log_ret.rolling(window=16).apply(get_hurst_exponent, raw=True)\n",
        "    data['h32'] = log_ret.rolling(window=32).apply(get_hurst_exponent, raw=True)\n",
        "    data['mh_diff'] = data['h32'] - data['h16']\n",
        "\n",
        "    delta = data['adjclose'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    data['rsi'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    data['ret_1d'] = data['adjclose'].pct_change()\n",
        "    data['vol_20'] = data['ret_1d'].rolling(20).std()\n",
        "\n",
        "    # TARGET (Exact Return)\n",
        "    data['target'] = data['ret_1d'].shift(-1)\n",
        "\n",
        "    data = data.dropna()\n",
        "    return data\n",
        "\n",
        "def remove_correlated_features(df, feature_cols, threshold=0.7):\n",
        "    print(\"\\nðŸ” CHECKING FEATURE CORRELATION...\")\n",
        "    df_feat = df[feature_cols]\n",
        "    corr_matrix = df_feat.corr().abs()\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "    return [f for f in feature_cols if f not in to_drop]\n",
        "\n",
        "def detect_regime(data_slice):\n",
        "    vol = data_slice['ret_1d'].std() * np.sqrt(252)\n",
        "    if vol > 0.30:\n",
        "        return \"High Volatility (Panic)\"\n",
        "    elif data_slice['adjclose'].iloc[-1] > data_slice['adjclose'].iloc[0]:\n",
        "        return \"Bull Market (Calm Up)\"\n",
        "    else:\n",
        "        return \"Bear Market (Calm Down)\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. ROLLING REGRESSION (Multi-Model with Train/Test)\n",
        "# ==============================================================================\n",
        "def run_rolling_regression(df, feature_cols):\n",
        "\n",
        "    print(f\"\\nðŸš€ STARTING ROLLING REGRESSION (Checking Overfitting)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    train_months = 24\n",
        "    test_months = 6\n",
        "    train_size = train_months * 21\n",
        "    test_size = test_months * 21\n",
        "\n",
        "    results = []\n",
        "\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "    }\n",
        "\n",
        "    start_index = 0\n",
        "    while start_index + train_size + test_size < len(df):\n",
        "\n",
        "        train_data = df.iloc[start_index : start_index + train_size]\n",
        "        test_data = df.iloc[start_index + train_size : start_index + train_size + test_size]\n",
        "\n",
        "        if len(test_data) == 0: break\n",
        "\n",
        "        # Normalize\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(train_data[feature_cols])\n",
        "        X_test = scaler.transform(test_data[feature_cols])\n",
        "        y_train = train_data['target']\n",
        "        y_test = test_data['target']\n",
        "\n",
        "        regime = detect_regime(test_data)\n",
        "\n",
        "        for model_name, model_obj in models.items():\n",
        "            model_obj.fit(X_train, y_train)\n",
        "\n",
        "            # --- TRAIN PERFORMANCE ---\n",
        "            pred_train = model_obj.predict(X_train)\n",
        "            rmse_train = np.sqrt(mean_squared_error(y_train, pred_train))\n",
        "\n",
        "            sig_train = np.where(pred_train > 0, 1, 0)\n",
        "            ret_train = sig_train * y_train\n",
        "            pnl_train = (1 + ret_train).cumprod().iloc[-1] - 1\n",
        "\n",
        "            # --- TEST PERFORMANCE ---\n",
        "            pred_test = model_obj.predict(X_test)\n",
        "            rmse_test = np.sqrt(mean_squared_error(y_test, pred_test))\n",
        "\n",
        "            sig_test = np.where(pred_test > 0, 1, 0)\n",
        "            ret_test = sig_test * y_test\n",
        "            pnl_test = (1 + ret_test).cumprod().iloc[-1] - 1\n",
        "\n",
        "            # --- GAP ---\n",
        "            # For RMSE, we want Train and Test to be close.\n",
        "            # If Train is 0.01 and Test is 0.05, that's overfitting.\n",
        "            rmse_gap = rmse_test - rmse_train\n",
        "\n",
        "            results.append({\n",
        "                'Period_Start': test_data.index[0],\n",
        "                'Period_End': test_data.index[-1],\n",
        "                'Model': model_name,\n",
        "                'Regime': regime,\n",
        "                'Train_RMSE': rmse_train,\n",
        "                'Test_RMSE': rmse_test,\n",
        "                'RMSE_Gap': rmse_gap, # Positive is normal, but shouldn't be too big\n",
        "                'Train_PnL': pnl_train,\n",
        "                'Test_PnL': pnl_test\n",
        "            })\n",
        "\n",
        "        start_index += test_size\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df['Year'] = results_df['Period_End'].dt.year\n",
        "\n",
        "    cols = ['Period_Start', 'Period_End', 'Model', 'Regime', 'Train_RMSE', 'Test_RMSE', 'RMSE_Gap', 'Train_PnL', 'Test_PnL', 'Year']\n",
        "    return results_df[cols]\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. MAIN EXECUTION\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"ðŸ“¥ Downloading Data...\")\n",
        "    raw_df = yf.download('AAPL', start='2010-01-01', end='2024-01-01', progress=False, auto_adjust=False)\n",
        "    if isinstance(raw_df.columns, pd.MultiIndex): raw_df.columns = raw_df.columns.droplevel(1)\n",
        "    raw_df.columns = [c.lower() for c in raw_df.columns]\n",
        "    raw_df['adjclose'] = raw_df['adj close'] if 'adj close' in raw_df.columns else raw_df['close']\n",
        "\n",
        "    df = prepare_features(raw_df)\n",
        "    features = ['ma_spread', 'mh_diff', 'h16', 'h32', 'vol_20', 'ret_1d', 'rsi']\n",
        "    final_features = remove_correlated_features(df, features, threshold=0.7)\n",
        "\n",
        "    results_df = run_rolling_regression(df, final_features)\n",
        "\n",
        "    # ==========================================================================\n",
        "    # DISPLAY RESULTS\n",
        "    # ==========================================================================\n",
        "\n",
        "    print(\"\\nðŸ“‰ PERIOD-BY-PERIOD RESULTS (Sample)\")\n",
        "    print(\"=\"*120)\n",
        "    # pd.options.display.float_format = '{:.5f}'.format # Precise for RMSE\n",
        "    print(results_df.head(5).to_string(index=False))\n",
        "    print(\"\\nðŸ“Š ML RESULTS SUMMARY (REGRESSION)\")\n",
        "    print(f\"Average PnL per period:   {results_df['Test_PnL'].mean():.2%}\")\n",
        "    print(f\"Average RMSE (Error):     {results_df['Test_RMSE'].mean():.5f}\")\n",
        "    # Baseline RMSE is not calculated or stored in this version of results_df, so commenting it out\n",
        "    # print(f\"Baseline RMSE (Zero):     {results_df['Baseline_RMSE'].mean():.5f}\")\n",
        "\n",
        "    print(\"\\nðŸ“Š REGRESSION SUMMARY (Average)\")\n",
        "    summary = results_df.groupby('Model')[['Train_RMSE', 'Test_RMSE', 'RMSE_Gap', 'Train_PnL', 'Test_PnL']].mean()\n",
        "    print(summary)\n",
        "\n",
        "     # 3. WIN RATE ANALYSIS (PER MODEL) - THE NEW PART\n",
        "    print(\"\\nðŸŽ¯ WIN RATE ANALYSIS (Per Model)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for model in results_df['Model'].unique():\n",
        "        # Filter for the specific model\n",
        "        model_data = results_df[results_df['Model'] == model]\n",
        "\n",
        "        # Calculate Wins (Where Test PnL > 0)\n",
        "        total_periods = len(model_data)\n",
        "        winning_periods = (model_data['Test_PnL'] > 0).sum()\n",
        "\n",
        "        # Calculate Percentage\n",
        "        if total_periods > 0:\n",
        "            win_rate = winning_periods / total_periods\n",
        "        else:\n",
        "            win_rate = 0.0\n",
        "\n",
        "        print(f\"   {model:<20}: {win_rate:.1%} ({winning_periods}/{total_periods} periods profitable)\")"
      ],
      "metadata": {
        "id": "ZPSElVVW1Vsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0bd18b9-3827-4f96-90aa-711251a55fe7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Downloading Data...\n",
            "ðŸ›  Generating Technical Features...\n",
            "\n",
            "ðŸ” CHECKING FEATURE CORRELATION...\n",
            "\n",
            "ðŸš€ STARTING ROLLING REGRESSION (Checking Overfitting)\n",
            "================================================================================\n",
            "\n",
            "ðŸ“‰ PERIOD-BY-PERIOD RESULTS (Sample)\n",
            "========================================================================================================================\n",
            "Period_Start Period_End             Model                  Regime  Train_RMSE  Test_RMSE  RMSE_Gap  Train_PnL  Test_PnL  Year\n",
            "  2012-08-06 2013-02-06 Linear Regression High Volatility (Panic)    0.016216   0.022880  0.006664   1.776568 -0.262639  2013\n",
            "  2012-08-06 2013-02-06     Random Forest High Volatility (Panic)    0.014967   0.023002  0.008035   4.159717 -0.187683  2013\n",
            "  2013-02-07 2013-08-07 Linear Regression Bear Market (Calm Down)    0.018678   0.015522 -0.003156   0.674338  0.074437  2013\n",
            "  2013-02-07 2013-08-07     Random Forest Bear Market (Calm Down)    0.017194   0.016731 -0.000463   3.686489 -0.076754  2013\n",
            "  2013-08-08 2014-02-06 Linear Regression   Bull Market (Calm Up)    0.018910   0.016466 -0.002444   0.790473  0.150920  2014\n",
            "\n",
            "ðŸ“Š ML RESULTS SUMMARY (REGRESSION)\n",
            "Average PnL per period:   8.43%\n",
            "Average RMSE (Error):     0.01789\n",
            "\n",
            "ðŸ“Š REGRESSION SUMMARY (Average)\n",
            "                   Train_RMSE  Test_RMSE  RMSE_Gap  Train_PnL  Test_PnL\n",
            "Model                                                                  \n",
            "Linear Regression    0.017495   0.017509  0.000014   1.021568  0.075762\n",
            "Random Forest        0.016143   0.018263  0.002119   3.452897  0.092802\n",
            "\n",
            "ðŸŽ¯ WIN RATE ANALYSIS (Per Model)\n",
            "============================================================\n",
            "   Linear Regression   : 77.3% (17/22 periods profitable)\n",
            "   Random Forest       : 77.3% (17/22 periods profitable)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ue7EvRJjWW3o"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}